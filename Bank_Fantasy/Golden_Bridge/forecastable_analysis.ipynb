{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecastable Analysis\n",
    "\n",
    "Similar to the Stationary Analysis, the analysis here is to double check the forecastability of those potential time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (14, 2)\n",
      "(100, 2) (10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>client_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>58743.49</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>73984.82</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>95749.55</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>118723.62</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-15</th>\n",
       "      <td>152350.76</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               purchase_amount  client_count\n",
       "purchase_date                               \n",
       "2019-02-11            58743.49           470\n",
       "2019-02-12            73984.82           686\n",
       "2019-02-13            95749.55           876\n",
       "2019-02-14           118723.62          1095\n",
       "2019-02-15           152350.76          1379"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train_df1 = pd.read_pickle('sample_train_df1.pkl')\n",
    "sample_test_df1 = pd.read_pickle('sample_test_df1.pkl')\n",
    "print(sample_train_df1.shape, sample_test_df1.shape)\n",
    "\n",
    "sample_train_df2 = pd.read_pickle('sample_train_df2.pkl')\n",
    "sample_test_df2 = pd.read_pickle('sample_test_df2.pkl')\n",
    "print(sample_train_df2.shape, sample_test_df2.shape)\n",
    "\n",
    "sample_train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_col = sample_train_df1['client_count']\n",
    "train2_col = sample_train_df2['client_count']\n",
    "test1_col = sample_test_df1['client_count']\n",
    "test2_col = sample_test_df2['client_count']\n",
    "\n",
    "# Sample 1 residuals\n",
    "decomposition1_train = seasonal_decompose(train1_col, model='multiplicative')\n",
    "decomposition1_test = seasonal_decompose(test1_col, model='multiplicative')\n",
    "residual1_train = decomposition1_train.resid.dropna()\n",
    "residual1_test = decomposition1_test.resid.dropna()\n",
    "\n",
    "# Sample 2 residuals - additive\n",
    "decomposition2_train_add = seasonal_decompose(train2_col, model='additive')\n",
    "decomposition2_test_add = seasonal_decompose(test2_col, model='additive', period=2)\n",
    "residual2_train_add = decomposition2_train_add.resid.dropna()\n",
    "residual2_test_add = decomposition2_test_add.resid.dropna()\n",
    "\n",
    "# Sample 2 residuals - multiplicative\n",
    "decomposition2_train_mulp = seasonal_decompose(train2_col, model='multiplicative')\n",
    "decomposition2_test_mulp = seasonal_decompose(test2_col, model='multiplicative', period=2)\n",
    "residual2_train_mulp = decomposition2_train_mulp.resid.dropna()\n",
    "residual2_test_mulp = decomposition2_test_mulp.resid.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Sample Entropy\n",
    "\n",
    "* \"Sample entropy (SampEn) is a measure of complexity of a sequence of value. For a given embedding dimension m, tolerance r and number of data points N, SampEn is the negative natural logarithm of the probability that if two sets of simultaneous data points of length m have distance <r then two sets of simultaneous data points of length m+1 also have distance <r.\"\n",
    "* Comparing to Approximate Entropy, Sample Entropy works better even for small set of sequence.\n",
    "* Lower the entropy value, less complexity, higher forecastability in time series.\n",
    "* Another benefit of sample entropy or approximate entropy is, the scale of the time series doesn't better, since it does the comparisons within each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampEn(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Sample entropy.\n",
    "    \n",
    "    U: time series data.\n",
    "    m: int, the length of compared run of data.\n",
    "    r: a positive real number, it specifies a filtering level.\n",
    "    \n",
    "    Reference: https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "    \"\"\"\n",
    "    N = len(U)\n",
    "    \n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for j in range(len(x)) if i != j and _maxdist(x[i], x[j]) <= r]) for i in range(len(x))]\n",
    "        return sum(C)\n",
    "    \n",
    "    return -np.log(_phi(m+1) / _phi(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22783839561841748 0.18301144988789228 0.13943250735323678\n",
      "1.8021222562636017 2.178532444324067\n"
     ]
    }
   ],
   "source": [
    "# original time series\n",
    "entropy_smp1 = SampEn(train1_col.values, m=2, r=0.2*np.std(train1_col.values))\n",
    "\n",
    "# logged original time series\n",
    "ts_log = np.log(train1_col)\n",
    "entropy_smp1_log = SampEn(ts_log.values, m=2, r=0.2*np.std(ts_log.values))\n",
    "\n",
    "# logged moving average time series\n",
    "ts_moving_avg = ts_log.rolling(window=4,center=False).mean().dropna()\n",
    "entropy_smp1_log_ma = SampEn(ts_moving_avg.values, m=2, r=0.2*np.std(ts_moving_avg.values))\n",
    "\n",
    "# residuals\n",
    "entropy_residuals = SampEn(residual1_train.values, m=2, r=0.2*np.std(residual1_train.values))\n",
    "\n",
    "# differenced residuals\n",
    "residuals_diff = residual1_train - residual1_train.shift(3) \n",
    "residuals_diff = residuals_diff.dropna()\n",
    "entropy_residuals_diff = SampEn(residuals_diff.values, m=2, r=0.2*np.std(residuals_diff.values))\n",
    "\n",
    "print(entropy_smp1, entropy_smp1_log, entropy_smp1_log_ma)\n",
    "print(entropy_residuals, entropy_residuals_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Comparing with the statistical values in Stationary Analysis, the output of sample entropy seems more determined.\n",
    "* It simply confirms that residuals are more complex than (processed) original time series, and logged moving average appears to be better than other time series sequences here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052854433903752 0.475845904869964 0.16911898215202087\n",
      "2.268683541318364 1.9136492868370918\n",
      "1.5553706911638245 1.739115735742633\n"
     ]
    }
   ],
   "source": [
    "# original time series\n",
    "entropy_smp2 = SampEn(train2_col.values, m=2, r=0.2*np.std(train2_col.values))\n",
    "\n",
    "# logged original time series\n",
    "ts_log = np.log(train2_col)\n",
    "entropy_smp2_log = SampEn(ts_log.values, m=2, r=0.2*np.std(ts_log.values))\n",
    "\n",
    "# logged moving average time series\n",
    "ts_moving_avg = ts_log.rolling(window=4,center=False).mean().dropna()\n",
    "entropy_smp2_log_ma = SampEn(ts_moving_avg.values, m=2, r=0.2*np.std(ts_moving_avg.values))\n",
    "\n",
    "# Additive residuals\n",
    "entropy_residuals_add = SampEn(residual2_train_add.values, m=2, r=0.2*np.std(residual2_train_add.values))\n",
    "\n",
    "# differenced additive residuals\n",
    "residuals_add_diff = residual2_train_add - residual2_train_add.shift(3) \n",
    "residuals_add_diff = residuals_add_diff.dropna()\n",
    "entropy_residuals_add_diff = SampEn(residuals_add_diff.values, m=2, r=0.2*np.std(residuals_add_diff.values))\n",
    "\n",
    "# Multiplicative residuals\n",
    "entropy_residuals_mulp = SampEn(residual2_train_mulp.values, m=2, r=0.2*np.std(residual2_train_mulp.values))\n",
    "\n",
    "# differenced multiplicative residuals\n",
    "residuals_mulp_diff = residual2_train_mulp - residual2_train_mulp.shift(3) \n",
    "residuals_mulp_diff = residuals_mulp_diff.dropna()\n",
    "entropy_residuals_mulp_diff = SampEn(residuals_mulp_diff.values, m=2, r=0.2*np.std(residuals_mulp_diff.values))\n",
    "\n",
    "print(entropy_smp2, entropy_smp2_log, entropy_smp2_log_ma)\n",
    "print(entropy_residuals_add, entropy_residuals_add_diff)\n",
    "print(entropy_residuals_mulp, entropy_residuals_mulp_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Comparing all the complexity of these time series, logged moving average of original time series still appears to be the most ideal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
